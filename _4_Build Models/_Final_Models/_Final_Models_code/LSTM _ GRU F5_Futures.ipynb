{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM & GRU F5_Futures.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"L1368ngqjFRE"},"source":["## 匯入相關套件"]},{"cell_type":"code","metadata":{"id":"pSYz8b8-fH3a"},"source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","import torch\n","import torch.nn as nn\n","\n","import time\n","import math\n","import os\n","from datetime import datetime\n","\n","import matplotlib.dates as mdates\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_style(\"darkgrid\")  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"od_HdO01jFRH"},"source":["# 確認是否可以使用 GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","gpu_available = torch.cuda.is_available()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Htfx5sRjFRH"},"source":["## 自定義函式、類別"]},{"cell_type":"code","metadata":{"id":"0JBhRR6gjFRI"},"source":["class LSTM(nn.Module):\n","\n","    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n","      \n","        super(LSTM, self).__init__()\n","        \n","        self.hidden_dim = hidden_dim \n","        self.num_layers = num_layers\n","        \n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        \n","    def forward(self, x):\n","        \n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device).requires_grad_()\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device).requires_grad_()\n","        \n","        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n","        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n","        out = self.fc(out[:, -1, :])\n","        \n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IB6JiMqijFRI"},"source":["class GRU(nn.Module):\n","  \n","    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n","        \n","        super(GRU, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        \n","        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        \n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device).requires_grad_()\n","        \n","        out, (hn) = self.gru(x, (h0.detach()))\n","        out = self.fc(out[:, -1, :])\n","        \n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qKE3bc7WjFRJ"},"source":["def stockoil(id):\n","\n","    # 取出石油期貨\n","    features1 = f[f['name']=='BrentOil'].loc[:,'close'].rename('brentOilClose').reset_index(drop=True)\n","    features2 = f[f['name']=='CrudeOil'].loc[:,'close'].rename('crudeOilClose').reset_index(drop=True)\n","\n","    stockdate = f[f['name']==str(id)].loc[:,'date']\n","\n","    # 表格合併\n","    stockdf = f[f['name']==str(id)].dropna(axis=1).loc[:,['open','high','low','close','volume']].reset_index(drop=True)\n","    stockdf1 = pd.concat([stockdf, features1, features2], ignore_index=False, axis=1)\n","\n","    \n","    return stockdf1, stockdate "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gAUwRB2J1Pst"},"source":["def stockship(id):\n","\n","    # 取出航運報價\n","    features = f[f['name']=='shippingIndex'].loc[:,['BCI','BCTI','BDI','BDTI','BPI','BSI']].reset_index(drop=True)\n","\n","    stockdate = f[f['name']==str(id)].loc[:,'date']\n","\n","    # 合併\n","    stockdf = f[f['name']==str(id)].dropna(axis=1).loc[:,['open','high','low','close','volume']].reset_index(drop=True)\n","    stockdf1 = pd.concat([stockdf, features], ignore_index=False, axis=1)\n","    \n","    return stockdf1, stockdate"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HTC8WTOT5dCE"},"source":["def stockiron(id):\n","    \n","    # 取出石油報價\n","    features = f[f['name']=='Iron'].loc[:,'close'].rename('ironClose').reset_index(drop=True)\n","    \n","    stockdate = f[f['name']==str(id)].loc[:,'date']\n","    \n","    stockdf = f[f['name']==str(id)].dropna(axis=1).loc[:,['open','high','low','close','volume']].reset_index(drop=True)\n","\n","    # 因為鐵礦石時間與其他不同，故以鐵礦石的時間為基準\n","    diff = len(stockdf)-len(features)\n","\n","    stockdf1 = stockdf.drop(stockdf.head(diff).index).reset_index(drop=True)\n","    stockdate = stockdate[diff:]\n","\n","    stockdf2 = pd.concat([stockdf1, features], ignore_index=False, axis=1)\n","    #print(df)\n","    \n","    return stockdf2, stockdate"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdQECdYsjFRK"},"source":["def split_data(stock, lookback, gapspace=0, test_set_size=120):\n","    \n","    # data_raw = stock.to_numpy() # convert to numpy array\n","    data_raw = stock\n","    data = []\n","    \n","    # create all possible sequences of length seq_len\n","    for index in range(len(data_raw) - lookback): \n","      \n","        data.append(data_raw[index: index + lookback,:])\n","    \n","    data = np.array(data);\n","\n","    # test_set_size = int(np.round(0.2*data.shape[0]));\n","    train_set_size = data.shape[0] - (test_set_size);\n","    \n","    x_train = data[:train_set_size,:-1-gapspace,:]\n","    y_train = data[:train_set_size,-1,3:4]\n","    x_test = data[train_set_size:,:-1-gapspace,:]\n","    y_test = data[train_set_size:,-1,3:4]\n","  \n","    x_train = torch.from_numpy(x_train).type(torch.Tensor)\n","    y_train= torch.from_numpy(y_train).type(torch.Tensor)\n","    x_test = torch.from_numpy(x_test).type(torch.Tensor)\n","    y_test= torch.from_numpy(y_test).type(torch.Tensor)\n","            \n","    x_train = x_train.to(device)\n","    y_train= y_train.to(device)\n","    x_test = x_test.to(device)\n","    y_test= y_test.to(device)\n","        \n","    return x_train, y_train, x_test, y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWM7oHYFjFRL"},"source":["def model_train_predict(ID=None, input_dim=None, epochs=500, model_name='LSTM',\n","             x_train=None, y_train=None, x_test=None, y_test=None, scalertar=None):\n","      \n","    mseloss_train = np.zeros(epochs)\n","    mseloss_test = np.zeros(epochs)\n","    all_y_train_pred = []\n","    all_y_test_pred = []\n","    \n","    if model_name == 'LSTM':\n","        \n","        model = LSTM(input_dim=input_dim, hidden_dim=32, output_dim=1, num_layers=2)\n","        model = model.to(device)\n","        \n","        criterion = torch.nn.MSELoss(reduction='mean')\n","        optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n","     \n","    if model_name == 'GRU':\n","        \n","        model = GRU(input_dim=input_dim, hidden_dim=32, output_dim=1, num_layers=2)\n","        model = model.to(device)\n","\n","        criterion = torch.nn.MSELoss(reduction='mean')\n","        optimiser = torch.optim.Adam(model.parameters(), lr=0.01)    \n","\n","    for i in range(epochs):\n","\n","        y_train_pred = model(x_train)\n","        loss = criterion(y_train_pred, y_train) \n","        \n","        if (i+1)%25 == 0:\n","            print(\"Epoch \", i+1, \"MSE: \", loss.item())\n","        mseloss_train[i] = loss.item()\n","\n","        if gpu_available == False:  \n","            all_y_train_pred.append(scalertar.inverse_transform(y_train_pred.detach().numpy()))    \n","        else:\n","            all_y_train_pred.append(scalertar.inverse_transform(y_train_pred.cpu().detach().numpy()))                \n","\n","        optimiser.zero_grad()\n","        loss.backward()\n","        optimiser.step()\n","\n","        y_test_pred = model(x_test)\n","        losst = criterion(y_test_pred, y_test) \n","        mseloss_test[i] = losst.item()\n","\n","        if gpu_available == False:\n","\n","            all_y_test_pred.append(scalertar.inverse_transform(y_test_pred.detach().numpy()))\n","\n","        else:\n","\n","            all_y_test_pred.append(scalertar.inverse_transform(y_test_pred.cpu().detach().numpy()))\n","            \n","    print('-'*80)        \n","    \n","    if os.path.exists('/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/model') is False:\n","        os.makedirs('/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/model')\n","    \n","    # 模型存檔\n","    path = f'/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/model/{ID}_{model_name}_epoch{epochs}.pth'\n","    torch.save(model.state_dict(), path)\n","    \n","    return all_y_train_pred, all_y_test_pred, mseloss_train, mseloss_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3UlpEgibjFRM"},"source":["def Train_Data_Stock_Trend_Plot(y_train, y_train_pred, train_date_list=None, ID=None, model_name=None):\n","    \n","    fig = plt.figure(figsize=(16, 12))\n","\n","    # 日期格式修正\n","    x= [datetime.strptime(str(d), '%Y-%m-%d').date() for d in train_date_list]\n","\n","    ax = sns.lineplot(x=x, y=y_train.ravel(), label=\"Historical Data\", color='royalblue')\n","    ax = sns.lineplot(x=x, y=y_train_pred.ravel(), label= f'{model_name} Train Prediction', color='tomato')\n","    ax.set_title(f'{ID}  {model_name} Train Data Stock Trend', size = 20, fontweight='bold')\n","    ax.set_xlabel('Year', size = 18)\n","    ax.set_ylabel('Stock Price (TWD)', size = 18)\n","    ax.set_xticklabels('', size=10)\n","    plt.legend(fontsize='xx-large', loc='upper left')\n","\n","    #设置 x 轴主刻度格式\n","    alldays =  mdates.YearLocator()                           #主刻度为每年\n","    ax.xaxis.set_major_locator(alldays)                       #设置主刻度\n","    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y')) \n","\n","    plt.legend(fontsize='xx-large', loc='upper left')\n","    plt.tick_params(labelsize = 16)\n","    #plt.gcf().autofmt_xdate()\n","\n","    if os.path.exists('/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/fig') is False:\n","      \n","        os.makedirs('/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/fig')\n","\n","    #plt.show()\n","    fig.savefig(f'/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/fig/{ID}_{model_name}_Train_Data_Stock_Trend.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GQQu7o1jFRM"},"source":["def Test_Data_Stock_Trend_Plot(y_test, y_test_pred, test_date_list=None, ID=None, model_name=None):\n","    \n","    fig = plt.figure(figsize=(16, 12))\n","\n","    x= [datetime.strptime(str(d), '%Y-%m-%d').date() for d in test_date_list]\n","\n","    ax = sns.lineplot(x=x, y=y_test.ravel(), label='Historical Data')\n","    ax = sns.lineplot(x=x, y=y_test_pred.ravel(), label=f'{model_name} Test Prediction')\n","    ax.set_title(f'{ID}  {model_name} Test Data Stock Trend', size = 20, fontweight='bold')\n","    ax.set_xlabel('Month', size = 18)\n","    ax.set_ylabel('Stock price (TWD)', size = 18)\n","\n","    alldays =  mdates.MonthLocator()                          \n","    ax.xaxis.set_major_locator(alldays)                       \n","    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m')) \n","\n","    plt.legend(fontsize='xx-large', loc='upper left')\n","    plt.tick_params(labelsize=16)\n","    #plt.gcf().autofmt_xdate()\n","\n","    if os.path.exists('/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/fig') is False:\n","      \n","        os.makedirs('/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/fig')\n","\n","    #plt.show()\n","    fig.savefig(f'/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/fig/{ID}_{model_name}_Test_Data_Stock_Trend.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kRQwzSDfjFRN"},"source":["def LSTM_GRU_Data_Stock_Trend_Plot(y_test, lstmdata, grudata, test_date_list=None, ID=None):\n","    \n","    fig = plt.figure(figsize=(16, 12))\n","\n","    x= [datetime.strptime(str(d), '%Y-%m-%d').date() for d in test_date_list]\n","\n","    ax = sns.lineplot(x=x, y=y_test.ravel(), label='Historical Data')\n","    ax = sns.lineplot(x=x, y=lstmdata.ravel(), label=f'LSTM Test Prediction')\n","    ax = sns.lineplot(x=x, y=grudata.ravel(), label=f'GRU Test Prediction')\n","    ax.set_title(f'{ID}  Test Data Stock Trend', size = 20, fontweight='bold')\n","    ax.set_xlabel('Month', size = 18)\n","    ax.set_ylabel('Stock price (TWD)', size = 18)\n","\n","    alldays =  mdates.MonthLocator()                          \n","    ax.xaxis.set_major_locator(alldays)                       \n","    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m')) \n","\n","    plt.legend(fontsize='xx-large', loc='upper left')\n","    plt.tick_params(labelsize=16)\n","    #plt.gcf().autofmt_xdate()\n","\n","    if os.path.exists('/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/fig') is False:\n","      \n","        os.makedirs('/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/fig')\n","\n","    #plt.show()\n","    fig.savefig(f'/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/fig/{ID}_Both_LSTM_GRU_Test_Data_Stock_Trend.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EKu6uuWcjFRN"},"source":["def RMSE_MSELOSS_Plot(allTrainRMSE, allTestRMSE, mseloss_train, mseloss_test, ID=None, model_name=None):\n","    \n","    fig = plt.figure()\n","    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n","\n","    plt.subplot(1, 2, 1)\n","    ax = sns.lineplot(data=allTrainRMSE, label='Train Data')\n","    ax = sns.lineplot(data=allTestRMSE, label='Test Data')\n","    ax.set_xlabel('Epoch', size = 16)\n","    ax.set_title(f'{ID}  {model_name} RMSE', size = 18, fontweight='bold')\n","    plt.tick_params(labelsize=14)\n","    plt.legend(fontsize='x-large', loc='upper right')\n","\n","    plt.subplot(1, 2, 2)\n","    ax = sns.lineplot(data=mseloss_train, label='Train Data')\n","    ax = sns.lineplot(data=mseloss_test, label='Test Data')\n","    ax.set_xlabel('Epoch', size = 16)\n","    ax.set_title(f'{ID}  {model_name} MSE Loss', size = 18, fontweight='bold')\n","    plt.tick_params(labelsize=14)\n","    plt.legend(fontsize='x-large', loc='upper right')\n","\n","    fig.set_figheight(6)\n","    fig.set_figwidth(16)\n","    \n","    if os.path.exists('/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/fig') is False:\n","      \n","        os.makedirs('/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/fig')\n","\n","    #plt.show()\n","    fig.savefig(f'/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/fig/{ID}_{model_name}_RMSE_MSELOSS.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuJ2W5GsjFRO"},"source":["def Stock_predict_process(ID, epochs, model_name, train_date_list=None, test_date_list=None):\n","\n","    # 單獨 close 值的 scaler -> scalertar\n","    scalertar = MinMaxScaler()\n","    scalertar_data = scalertar.fit_transform(df.iloc[:,3].values.reshape(-1, 1))\n","\n","    # 全部進行 scaler\n","    scaler = MinMaxScaler()\n","    scaler_data = scaler.fit_transform(df.values)\n","\n","    # 分割資料，訓練維度(總天數, 以幾天來預測最後一天股價的天數，特徵值數量)，目標維度(總天數, 幾天後的股價值)\n","    x_train, y_train, x_test, y_test = split_data(scaler_data, lookback=lookback, gapspace=0, test_set_size=test_set_size)\n","\n","    # 放入模型並訓練，得到預測值\n","    all_y_train_pred, all_y_test_pred, mseloss_train, mseloss_test = model_train_predict(ID=ID, input_dim=df.shape[1], \n","                                                 epochs=epochs, model_name=model_name, \n","                                                 x_train=x_train, y_train=y_train, \n","                                                 x_test=x_test, y_test=y_test, \n","                                                 scalertar=scalertar)\n","\n","    # 將 tensor 換回 numpy\n","    if gpu_available == False:\n","\n","        y_train = scalertar.inverse_transform(y_train.detach().numpy())\n","        y_test = scalertar.inverse_transform(y_test.detach().numpy())\n","\n","    else:\n","\n","        y_train = scalertar.inverse_transform(y_train.cpu().detach().numpy())\n","        y_test = scalertar.inverse_transform(y_test.cpu().detach().numpy())\n","\n","    # 算出每一個 epoch 中 訓練與測試的 RMSE值\n","    allTrainRMSE = []\n","    allTestRMSE = []\n","\n","    for i in range(len(all_y_train_pred)):\n","      \n","        allTrainRMSE.append(math.sqrt(mean_squared_error(y_train[:,0], all_y_train_pred[i][:,0])))\n","        allTestRMSE.append(math.sqrt(mean_squared_error(y_test[:,0], all_y_test_pred[i][:,0])))\n","\n","\n","    # 畫圖\n","    # Train_Data_Stock_Trend_Plot\n","    Train_Data_Stock_Trend_Plot(y_train, all_y_train_pred[-1], train_date_list=train_date_list, ID=ID, model_name=model_name)\n","    \n","    # RMSE_MSELOSS_Plot\n","    RMSE_MSELOSS_Plot(allTrainRMSE, allTestRMSE, mseloss_train, mseloss_test, ID=ID, model_name=model_name)\n","    \n","    dfmseplot = pd.DataFrame({f'allTrainRMSE_{model_name}':allTrainRMSE,\n","                          f'allTestRMSE_{model_name}':allTestRMSE,\n","                          f'mseloss_train_{model_name}':mseloss_train,\n","                          f'mseloss_test_{model_name}':mseloss_test})\n","    \n","    # Test_Data_Stock_Trend_Plot    \n","    Test_Data_Stock_Trend_Plot(y_test, all_y_test_pred[-1], test_date_list=test_date_list, ID=ID, model_name=model_name)\n","    \n","    dfpred = pd.DataFrame({'date':train_date_list + test_date_list,\n","                       'split':['train']*len(train_date_list) + ['test']*len(test_date_list),\n","                       'historical':list(y_train.ravel()) + list(y_test.ravel()),\n","                       f'prediction_{model_name}':list(all_y_train_pred[-1].ravel()) + list(all_y_test_pred[-1].ravel())})\n","    \n","    \n","    # 計算 RMSE, R2, AdjR2\n","    trainRMSE = math.sqrt(mean_squared_error(y_train[:,0], all_y_train_pred[i][:,0]))\n","    testRMSE = math.sqrt(mean_squared_error(y_test[:,0], all_y_test_pred[i][:,0]))\n","    \n","    trainR2 = r2_score(y_train[:,0], all_y_train_pred[-1][:,0])\n","    testR2 = r2_score(y_test[:,0], all_y_test_pred[-1][:,0])\n","\n","    trainAdjR2 = 1-(1-trainR2)*((len(x_train)-1)/(len(x_train)-x_train.shape[2]-1))\n","    testAdjR2 = 1-(1-testR2)*((len(x_test)-1)/(len(x_test)-x_test.shape[2]-1))\n","\n","    dfscore = pd.DataFrame({'name':[f'{ID}', f'{ID}'],\n","                            'modelname':[f'{model_name}', f'{model_name}'],\n","                            'split': ['Train', 'Test'],\n","                            'RMSE': [trainRMSE, testRMSE],\n","                            'R2 Score': [trainR2, testR2],\n","                            'Adj R2 Score': [trainAdjR2, testAdjR2]})\n","\n","    return dfmseplot, dfpred, dfscore"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eH8RPIj2jFRO"},"source":["# START"]},{"cell_type":"code","metadata":{"id":"7n9RZ6eEjFRO"},"source":["# 檔案讀取大表\n","f = pd.read_csv('/content/drive/MyDrive/Final Project/Final_Dataset/Second clean in Spark/clean_long_dataset.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C3qnlB1WjFRO"},"source":["# 列出所有股票\n","names = list(f['name'].unique())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gt3hDTRRjFRP"},"source":["# 紀錄一下各自的時間\n","timelist = []\n","metrics_score = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"0lSjjekAjFRP"},"source":["for name in names[:30]:\n","    \n","    # 參數設定\n","    ID = name \n","    lookback = 10\n","    test_set_size = 120\n","    epochs = 500\n","\n","    # 選取想要的股票\n","    # df, alldate = stock(ID)\n","    if name in names[:10]:\n","\n","      df, alldate = stockoil(ID)\n","\n","    elif name in names[10:20]:\n","\n","      df, alldate = stockiron(ID)\n","\n","    else:\n","\n","      df, alldate = stockship(ID)\n","\n","    # 保留日期資訊\n","    alldatelist = list(alldate)\n","    train_date_list = alldatelist[lookback:-test_set_size]\n","    test_date_list = alldatelist[-test_set_size:]\n","\n","    # LSTM\n","    lstmstart = time.time()\n","    lstmdfmseplot, lstmdfpred, lstmdfscore = Stock_predict_process(ID, epochs, model_name = 'LSTM', \n","                                     train_date_list=train_date_list, test_date_list=test_date_list)\n","    lstmend = time.time()\n","    timelist.append(lstmend - lstmstart)\n","    timelist.append(lstmend - lstmstart) # 為了後面整理資料\n","\n","    # GRU\n","    grustart = time.time()\n","    grudfmseplot, grudfpred, grudfscore = Stock_predict_process(ID, epochs, model_name = 'GRU', \n","                                    train_date_list=train_date_list, test_date_list=test_date_list)\n","    gruend = time.time()\n","    timelist.append(gruend - grustart)\n","    timelist.append(gruend - grustart)  # 為了後面整理資料\n","\n","    # LSTM_GRU_Data_Stock_Trend_Plot\n","    LSTM_GRU_Data_Stock_Trend_Plot(lstmdfpred[lstmdfpred['split']=='test'].loc[:,'historical'].values,\n","                         lstmdfpred[lstmdfpred['split']=='test'].loc[:,'prediction_LSTM'].values, \n","                         grudfpred[grudfpred['split']=='test'].loc[:,'prediction_GRU'].values,\n","                         test_date_list=test_date_list, ID=ID)\n","\n","    # 存檔\n","    dfpred = pd.concat([lstmdfpred, grudfpred.loc[:,'prediction_GRU']], axis=1)\n","    dfmseplot = pd.concat([lstmdfmseplot, grudfmseplot], axis=1)\n","    dfscore = pd.concat([lstmdfscore, grudfscore]).reset_index(drop=True)\n","\n","    if os.path.exists('/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/researchdata') is False:\n","      \n","        os.makedirs('/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/researchdata')\n","\n","    dfpred.to_csv(f'/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/researchdata/{ID}_Prediction_Data.csv', index=False)\n","    dfmseplot.to_csv(f'/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/researchdata/{ID}_RMSE_MSELOSS_in_Training.csv', index=False)\n","    \n","    #dfscore.to_csv(f'data/researchdata/{ID}_Metrics_and_Score_.csv', index=False)\n","    metrics_score.append(dfscore)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rjAWZP-WjFRQ"},"source":["all_metrics_score = pd.concat([x for x in metrics_score]).reset_index(drop=True)\n","all_metrics_score.insert(len(all_metrics_score.columns), 'time', timelist)\n","all_metrics_score.to_csv(f'/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/researchdata/All_Metrics_Score_Time.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"twHrInizjFRQ"},"source":["lstm_time = []\n","gru_time = []\n","\n","for i in range(len(timelist)):   \n","\n","    if i%4 == 0:\n","\n","        lstm_time.append(timelist[i])\n","\n","    if i%4 == 2:\n","      \n","        gru_time.append(timelist[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OGmpTOxjjFRQ"},"source":["dfalltime = pd.DataFrame({'name':names[:30],\n","              'lstm_time':lstm_time,\n","              'gru_time':gru_time})\n","\n","dfalltime.to_csv(f'/content/drive/MyDrive/Final Project/LSTM/v7 data/LSTM_Future/researchdata/All_Time.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"96jSUBcDjFRR"},"source":["##### just test"]}]}