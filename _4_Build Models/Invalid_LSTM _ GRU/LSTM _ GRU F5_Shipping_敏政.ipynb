{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM 200 Try_v8 for test_敏政.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Z7VKteTKzZtq"},"source":["## 匯入相關套件"]},{"cell_type":"code","metadata":{"id":"pSYz8b8-fH3a"},"source":["import numpy as np\n","import pandas as pd\n","\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","import torch\n","import torch.nn as nn\n","\n","import time\n","import math\n","import os\n","from datetime import datetime\n","\n","import matplotlib.dates as mdates\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_style(\"darkgrid\")  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gxeti6nXzZtu"},"source":["# 確認是否可以使用 GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","gpu_available = torch.cuda.is_available()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yZQUiF59zZtv"},"source":["## 自定義函式、類別"]},{"cell_type":"code","metadata":{"id":"N41BnupnzZtv"},"source":["class LSTM(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n","        super(LSTM, self).__init__()\n","        \n","        self.hidden_dim = hidden_dim \n","        self.num_layers = num_layers\n","        \n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        \n","    def forward(self, x):\n","        \n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device).requires_grad_()\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device).requires_grad_()\n","        \n","        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n","        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n","        out = self.fc(out[:, -1, :])\n","        \n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r6p3XyYjzZtw"},"source":["class GRU(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n","        \n","        super(GRU, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        \n","        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        \n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device).requires_grad_()\n","        \n","        out, (hn) = self.gru(x, (h0.detach()))\n","        out = self.fc(out[:, -1, :])\n","        \n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"To2-pYe6zZtw"},"source":["def stock(id):\n","    \n","    stockdate = f[f['name']==str(id)].loc[:,'date']\n","    stockdf = f[f['name']==str(id)].dropna(axis=1).loc[:,'open':'volume']\n","    \n","    # 取出在clean_long_data.csv裡面的航運指數\n","    futures_shipping = f[f['category']=='Futures'].loc[:,'BCI','BCTI','BDI','BDTI','BPI','BSI']\n","\n","    #print(df)\n","    \n","    return stockdf, stockdate"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8yl38XFTiZV","executionInfo":{"status":"ok","timestamp":1627267830570,"user_tz":-480,"elapsed":465,"user":{"displayName":"group bdse","photoUrl":"","userId":"17605883566341682608"}},"outputId":"0476806e-5871-4b71-e50a-d2f2c654e230"},"source":["stockdate = f[f['name']==str(id)].loc[:,'date']\n","print(stockdate)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Series([], Name: date, dtype: object)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jk4Iw_A73led"},"source":["stockdf = f[f['name']=='2603.TW'].dropna(axis=1).loc[:,'open':'volume']\n","stockdf = stockdf.reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AnShMazNRMTl"},"source":["futures_shipping = f[f['name']=='shippingIndex'].loc[:,'BCI':'BSI']\n","futures_shipping =  futures_shipping.reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"SY14G1QbQc5O","executionInfo":{"status":"ok","timestamp":1627270982517,"user_tz":-480,"elapsed":303,"user":{"displayName":"group bdse","photoUrl":"","userId":"17605883566341682608"}},"outputId":"efc71fae-0b1f-409c-e364-6db2f6b5c512"},"source":["lstm_shippingIndex = pd.concat([stockdf, futures_shipping], axis = 1, ignore_index = False)\n","lstm_shippingIndex"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>volume</th>\n","      <th>BCI</th>\n","      <th>BCTI</th>\n","      <th>BDI</th>\n","      <th>BDTI</th>\n","      <th>BPI</th>\n","      <th>BSI</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>20.587770</td>\n","      <td>20.626325</td>\n","      <td>19.970908</td>\n","      <td>20.009462</td>\n","      <td>41269499.0</td>\n","      <td>1604.0</td>\n","      <td>793.0</td>\n","      <td>1329.0</td>\n","      <td>785.0</td>\n","      <td>1615.0</td>\n","      <td>1408.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20.279338</td>\n","      <td>20.279338</td>\n","      <td>19.238384</td>\n","      <td>19.662477</td>\n","      <td>28470080.0</td>\n","      <td>1633.0</td>\n","      <td>781.0</td>\n","      <td>1349.0</td>\n","      <td>783.0</td>\n","      <td>1666.0</td>\n","      <td>1413.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.431154</td>\n","      <td>19.816692</td>\n","      <td>19.315492</td>\n","      <td>19.546814</td>\n","      <td>15967934.0</td>\n","      <td>1651.0</td>\n","      <td>772.0</td>\n","      <td>1369.0</td>\n","      <td>781.0</td>\n","      <td>1711.0</td>\n","      <td>1416.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>19.546814</td>\n","      <td>19.855247</td>\n","      <td>19.469709</td>\n","      <td>19.855247</td>\n","      <td>9984286.0</td>\n","      <td>1690.0</td>\n","      <td>748.0</td>\n","      <td>1398.0</td>\n","      <td>782.0</td>\n","      <td>1755.0</td>\n","      <td>1429.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>19.855249</td>\n","      <td>19.855249</td>\n","      <td>19.276940</td>\n","      <td>19.508263</td>\n","      <td>15785273.0</td>\n","      <td>1759.0</td>\n","      <td>742.0</td>\n","      <td>1446.0</td>\n","      <td>781.0</td>\n","      <td>1832.0</td>\n","      <td>1440.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2431</th>\n","      <td>136.500000</td>\n","      <td>152.000000</td>\n","      <td>136.000000</td>\n","      <td>152.000000</td>\n","      <td>133713564.0</td>\n","      <td>3861.0</td>\n","      <td>450.0</td>\n","      <td>3175.0</td>\n","      <td>624.0</td>\n","      <td>3515.0</td>\n","      <td>2864.0</td>\n","    </tr>\n","    <tr>\n","      <th>2432</th>\n","      <td>157.000000</td>\n","      <td>160.000000</td>\n","      <td>151.000000</td>\n","      <td>160.000000</td>\n","      <td>134596407.0</td>\n","      <td>3987.0</td>\n","      <td>449.0</td>\n","      <td>3255.0</td>\n","      <td>624.0</td>\n","      <td>3642.0</td>\n","      <td>2877.0</td>\n","    </tr>\n","    <tr>\n","      <th>2433</th>\n","      <td>168.000000</td>\n","      <td>176.000000</td>\n","      <td>168.000000</td>\n","      <td>176.000000</td>\n","      <td>92307564.0</td>\n","      <td>4021.0</td>\n","      <td>451.0</td>\n","      <td>3324.0</td>\n","      <td>614.0</td>\n","      <td>3827.0</td>\n","      <td>2899.0</td>\n","    </tr>\n","    <tr>\n","      <th>2434</th>\n","      <td>180.000000</td>\n","      <td>185.000000</td>\n","      <td>170.000000</td>\n","      <td>179.500000</td>\n","      <td>147367246.0</td>\n","      <td>4136.0</td>\n","      <td>449.0</td>\n","      <td>3418.0</td>\n","      <td>605.0</td>\n","      <td>4010.0</td>\n","      <td>2921.0</td>\n","    </tr>\n","    <tr>\n","      <th>2435</th>\n","      <td>181.500000</td>\n","      <td>197.000000</td>\n","      <td>181.500000</td>\n","      <td>197.000000</td>\n","      <td>124635805.0</td>\n","      <td>3931.0</td>\n","      <td>447.0</td>\n","      <td>3383.0</td>\n","      <td>598.0</td>\n","      <td>4119.0</td>\n","      <td>2930.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2436 rows × 11 columns</p>\n","</div>"],"text/plain":["            open        high         low  ...   BDTI     BPI     BSI\n","0      20.587770   20.626325   19.970908  ...  785.0  1615.0  1408.0\n","1      20.279338   20.279338   19.238384  ...  783.0  1666.0  1413.0\n","2      19.431154   19.816692   19.315492  ...  781.0  1711.0  1416.0\n","3      19.546814   19.855247   19.469709  ...  782.0  1755.0  1429.0\n","4      19.855249   19.855249   19.276940  ...  781.0  1832.0  1440.0\n","...          ...         ...         ...  ...    ...     ...     ...\n","2431  136.500000  152.000000  136.000000  ...  624.0  3515.0  2864.0\n","2432  157.000000  160.000000  151.000000  ...  624.0  3642.0  2877.0\n","2433  168.000000  176.000000  168.000000  ...  614.0  3827.0  2899.0\n","2434  180.000000  185.000000  170.000000  ...  605.0  4010.0  2921.0\n","2435  181.500000  197.000000  181.500000  ...  598.0  4119.0  2930.0\n","\n","[2436 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQabK5y20-NI","executionInfo":{"status":"ok","timestamp":1627267805172,"user_tz":-480,"elapsed":21152,"user":{"displayName":"group bdse","photoUrl":"","userId":"17605883566341682608"}},"outputId":"f62678b9-619e-424c-951b-0839cd528a40"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hHdRkMwwzZtx"},"source":["def split_data(stock, lookback, gapspace=0, test_set_size=120):\n","    \n","    # data_raw = stock.to_numpy() # convert to numpy array\n","    data_raw = stock\n","    data = []\n","    \n","    # create all possible sequences of length seq_len\n","    for index in range(len(data_raw) - lookback): \n","        data.append(data_raw[index: index + lookback,:])\n","    \n","    data = np.array(data);\n","\n","    # test_set_size = int(np.round(0.2*data.shape[0]));\n","    train_set_size = data.shape[0] - (test_set_size);\n","    \n","    x_train = data[:train_set_size,:-1-gapspace,:]\n","    y_train = data[:train_set_size,-1,3:4]\n","    x_test = data[train_set_size:,:-1-gapspace,:]\n","    y_test = data[train_set_size:,-1,3:4]\n","    \n","    print('x_train.shape = ',x_train.shape)\n","    print('y_train.shape = ',y_train.shape)\n","    print('x_test.shape = ',x_test.shape)\n","    print('y_test.shape = ',y_test.shape)\n","    print('-'*80)\n","  \n","    x_train = torch.from_numpy(x_train).type(torch.Tensor)\n","    y_train= torch.from_numpy(y_train).type(torch.Tensor)\n","    x_test = torch.from_numpy(x_test).type(torch.Tensor)\n","    y_test= torch.from_numpy(y_test).type(torch.Tensor)\n","            \n","    x_train = x_train.to(device)\n","    y_train= y_train.to(device)\n","    x_test = x_test.to(device)\n","    y_test= y_test.to(device)\n","        \n","    return x_train, y_train, x_test, y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQ1-p77SzZty"},"source":["def model_train_predict(ID=None, input_dim=None, epochs=500, model_name='LSTM',\n","                        x_train=None, y_train=None, x_test=None, y_test=None, scalertar=None):\n","      \n","    mseloss_train = np.zeros(epochs)\n","    mseloss_test = np.zeros(epochs)\n","    all_y_train_pred = []\n","    all_y_test_pred = []\n","    \n","    if model_name == 'LSTM':\n","        \n","        model = LSTM(input_dim=input_dim, hidden_dim=32, output_dim=1, num_layers=2)\n","        model = model.to(device)\n","        \n","        criterion = torch.nn.MSELoss(reduction='mean')\n","        optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n","     \n","    if model_name == 'GRU':\n","        \n","        model = GRU(input_dim=input_dim, hidden_dim=32, output_dim=1, num_layers=2)\n","        model = model.to(device)\n","\n","        criterion = torch.nn.MSELoss(reduction='mean')\n","        optimiser = torch.optim.Adam(model.parameters(), lr=0.01)    \n","\n","    for i in range(epochs):\n","\n","        y_train_pred = model(x_train)\n","        loss = criterion(y_train_pred, y_train) \n","        if (i+1)%25 == 0:\n","            print(\"Epoch \", i+1, \"MSE: \", loss.item())\n","        mseloss_train[i] = loss.item()\n","\n","        if gpu_available == False:  \n","            all_y_train_pred.append(scalertar.inverse_transform(y_train_pred.detach().numpy()))    \n","        else:\n","            all_y_train_pred.append(scalertar.inverse_transform(y_train_pred.cpu().detach().numpy()))                \n","\n","        optimiser.zero_grad()\n","        loss.backward()\n","        optimiser.step()\n","\n","        y_test_pred = model(x_test)\n","        losst = criterion(y_test_pred, y_test) \n","        mseloss_test[i] = losst.item()\n","\n","        if gpu_available == False:\n","            all_y_test_pred.append(scalertar.inverse_transform(y_test_pred.detach().numpy()))\n","        else:\n","            all_y_test_pred.append(scalertar.inverse_transform(y_test_pred.cpu().detach().numpy()))\n","            \n","    print('-'*80)        \n","    \n","    if os.path.exists('data/model') is False:\n","        os.makedirs('data/model')\n","    \n","    # 模型存檔\n","    path = f'data/model/{ID}_{model_name}_epoch{epochs}.pth'\n","    torch.save(model.state_dict(), path)\n","    \n","    return all_y_train_pred, all_y_test_pred, mseloss_train, mseloss_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v4fWdzmWzZtz"},"source":["def Train_Data_Stock_Trend_Plot(y_train, y_train_pred, train_date_list=None, ID=None, model_name=None):\n","    \n","    fig = plt.figure(figsize=(16, 12))\n","\n","    # 日期格式修正\n","    x= [datetime.strptime(str(d), '%Y-%m-%d').date() for d in train_date_list]\n","\n","    ax = sns.lineplot(x=x, y=y_train.ravel(), label=\"Historical Data\", color='royalblue')\n","    ax = sns.lineplot(x=x, y=y_train_pred.ravel(), label= f'{model_name} Train Prediction', color='tomato')\n","    ax.set_title(f'{ID}  {model_name} Train Data Stock Trend', size = 20, fontweight='bold')\n","    ax.set_xlabel('Year', size = 18)\n","    ax.set_ylabel('Stock Price (TWD)', size = 18)\n","    ax.set_xticklabels('', size=10)\n","    plt.legend(fontsize='xx-large', loc='upper left')\n","\n","    #设置 x 轴主刻度格式\n","    alldays =  mdates.YearLocator()                           #主刻度为每年\n","    ax.xaxis.set_major_locator(alldays)                       #设置主刻度\n","    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y')) \n","\n","    plt.legend(fontsize='xx-large', loc='upper left')\n","    plt.tick_params(labelsize = 16)\n","    #plt.gcf().autofmt_xdate()\n","\n","    if os.path.exists('data/fig') is False:\n","        os.makedirs('data/fig')\n","\n","    #plt.show()\n","    fig.savefig(f'data/fig/{ID}_{model_name}_Train_Data_Stock_Trend.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ku4InMKJzZt0"},"source":["def Test_Data_Stock_Trend_Plot(y_test, y_test_pred, test_date_list=None, ID=None, model_name=None):\n","    \n","    fig = plt.figure(figsize=(16, 12))\n","\n","    x= [datetime.strptime(str(d), '%Y-%m-%d').date() for d in test_date_list]\n","\n","    ax = sns.lineplot(x=x, y=y_test.ravel(), label='Historical Data')\n","    ax = sns.lineplot(x=x, y=y_test_pred.ravel(), label=f'{model_name} Test Prediction')\n","    ax.set_title(f'{ID}  {model_name} Test Data Stock Trend', size = 20, fontweight='bold')\n","    ax.set_xlabel('Month', size = 18)\n","    ax.set_ylabel('Stock price (TWD)', size = 18)\n","\n","    alldays =  mdates.MonthLocator()                          \n","    ax.xaxis.set_major_locator(alldays)                       \n","    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m')) \n","\n","    plt.legend(fontsize='xx-large', loc='upper left')\n","    plt.tick_params(labelsize=16)\n","    #plt.gcf().autofmt_xdate()\n","\n","    if os.path.exists('data/fig') is False:\n","        os.makedirs('data/fig')\n","\n","    #plt.show()\n","    fig.savefig(f'data/fig/{ID}_{model_name}_Test_Data_Stock_Trend.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h1frn9wIzZt0"},"source":["def LSTM_GRU_Data_Stock_Trend_Plot(y_test, lstmdata, grudata, test_date_list=None, ID=None):\n","    \n","    fig = plt.figure(figsize=(16, 12))\n","\n","    x= [datetime.strptime(str(d), '%Y-%m-%d').date() for d in test_date_list]\n","\n","    ax = sns.lineplot(x=x, y=y_test.ravel(), label='Historical Data')\n","    ax = sns.lineplot(x=x, y=lstmdata.ravel(), label=f'LSTM Test Prediction')\n","    ax = sns.lineplot(x=x, y=grudata.ravel(), label=f'GRU Test Prediction')\n","    ax.set_title(f'{ID}  Test Data Stock Trend', size = 20, fontweight='bold')\n","    ax.set_xlabel('Month', size = 18)\n","    ax.set_ylabel('Stock price (TWD)', size = 18)\n","\n","    alldays =  mdates.MonthLocator()                          \n","    ax.xaxis.set_major_locator(alldays)                       \n","    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m')) \n","\n","    plt.legend(fontsize='xx-large', loc='upper left')\n","    plt.tick_params(labelsize=16)\n","    #plt.gcf().autofmt_xdate()\n","\n","    if os.path.exists('data/fig') is False:\n","        os.makedirs('data/fig')\n","\n","    #plt.show()\n","    fig.savefig(f'data/fig/{ID}_Both_LSTM_GRU_Test_Data_Stock_Trend.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4pINGL3lzZt1"},"source":["def RMSE_MSELOSS_Plot(allTrainRMSE, allTestRMSE, mseloss_train, mseloss_test, ID=None, model_name=None):\n","    \n","    fig = plt.figure()\n","    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n","\n","    plt.subplot(1, 2, 1)\n","    ax = sns.lineplot(data=allTrainRMSE, label='Train Data')\n","    ax = sns.lineplot(data=allTestRMSE, label='Test Data')\n","    ax.set_xlabel('Epoch', size = 16)\n","    ax.set_title(f'{ID}  {model_name} RMSE', size = 18, fontweight='bold')\n","    plt.tick_params(labelsize=14)\n","    plt.legend(fontsize='x-large', loc='upper right')\n","\n","    plt.subplot(1, 2, 2)\n","    ax = sns.lineplot(data=mseloss_train, label='Train Data')\n","    ax = sns.lineplot(data=mseloss_test, label='Test Data')\n","    ax.set_xlabel('Epoch', size = 16)\n","    ax.set_title(f'{ID}  {model_name} MSE Loss', size = 18, fontweight='bold')\n","    plt.tick_params(labelsize=14)\n","    plt.legend(fontsize='x-large', loc='upper right')\n","\n","    fig.set_figheight(6)\n","    fig.set_figwidth(16)\n","    \n","    if os.path.exists('data/fig') is False:\n","        os.makedirs('data/fig')\n","\n","    #plt.show()\n","    fig.savefig(f'data/fig/{ID}_{model_name}_RMSE_MSELOSS.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1FKJjYJ5zZt2"},"source":["def Stock_predict_process(ID, epochs, model_name, train_date_list=None, test_date_list=None):\n","\n","    # 單獨 close 值的 scaler -> scalertar\n","    scalertar = MinMaxScaler()\n","    scalertar_data = scalertar.fit_transform(df.iloc[:,3].values.reshape(-1, 1))\n","\n","    # 全部進行 scaler\n","    scaler = MinMaxScaler()\n","    scaler_data = scaler.fit_transform(df.values)\n","\n","    # 分割資料，訓練維度(總天數, 以幾天來預測最後一天股價的天數，特徵值數量)，目標維度(總天數, 幾天後的股價值)\n","    x_train, y_train, x_test, y_test = split_data(scaler_data, lookback=lookback, gapspace=0, test_set_size=test_set_size)\n","\n","    # 放入模型並訓練，得到預測值\n","    all_y_train_pred, all_y_test_pred, mseloss_train, mseloss_test = model_train_predict(ID=ID, input_dim=df.shape[1], \n","                                                                                         epochs=epochs, model_name=model_name, \n","                                                                                         x_train=x_train, y_train=y_train, \n","                                                                                         x_test=x_test, y_test=y_test, \n","                                                                                         scalertar=scalertar)\n","\n","    # 將 tensor 換回 numpy\n","    if gpu_available == False:\n","        y_train = scalertar.inverse_transform(y_train.detach().numpy())\n","        y_test = scalertar.inverse_transform(y_test.detach().numpy())    \n","    else:\n","        y_train = scalertar.inverse_transform(y_train.cpu().detach().numpy())\n","        y_test = scalertar.inverse_transform(y_test.cpu().detach().numpy())\n","\n","    # 算出每一個 epoch 中 訓練與測試的 RMSE值\n","    allTrainRMSE = []\n","    allTestRMSE = []\n","\n","    for i in range(len(all_y_train_pred)):\n","        allTrainRMSE.append(math.sqrt(mean_squared_error(y_train[:,0], all_y_train_pred[i][:,0])))\n","        allTestRMSE.append(math.sqrt(mean_squared_error(y_test[:,0], all_y_test_pred[i][:,0])))\n","\n","\n","    # 畫圖\n","    # Train_Data_Stock_Trend_Plot\n","    Train_Data_Stock_Trend_Plot(y_train, all_y_train_pred[-1], train_date_list=train_date_list, ID=ID, model_name=model_name)\n","    \n","    # RMSE_MSELOSS_Plot\n","    RMSE_MSELOSS_Plot(allTrainRMSE, allTestRMSE, mseloss_train, mseloss_test, ID=ID, model_name=model_name)\n","    \n","    dfmseplot = pd.DataFrame({f'allTrainRMSE_{model_name}':allTrainRMSE,\n","                          f'allTestRMSE_{model_name}':allTestRMSE,\n","                          f'mseloss_train_{model_name}':mseloss_train,\n","                          f'mseloss_test_{model_name}':mseloss_test})\n","    \n","    # Test_Data_Stock_Trend_Plot    \n","    Test_Data_Stock_Trend_Plot(y_test, all_y_test_pred[-1], test_date_list=test_date_list, ID=ID, model_name=model_name)\n","    \n","    dfpred = pd.DataFrame({'date':train_date_list + test_date_list,\n","                       'split':['train']*len(train_date_list) + ['test']*len(test_date_list),\n","                       'historical':list(y_train.ravel()) + list(y_test.ravel()),\n","                       f'prediction_{model_name}':list(all_y_train_pred[-1].ravel()) + list(all_y_test_pred[-1].ravel())})\n","    \n","    \n","    # 計算 RMSE, R2, AdjR2\n","    trainRMSE = math.sqrt(mean_squared_error(y_train[:,0], all_y_train_pred[i][:,0]))\n","    testRMSE = math.sqrt(mean_squared_error(y_test[:,0], all_y_test_pred[i][:,0]))\n","    \n","    trainR2 = r2_score(y_train[:,0], all_y_train_pred[-1][:,0])\n","    testR2 = r2_score(y_test[:,0], all_y_test_pred[-1][:,0])\n","\n","    trainAdjR2 = 1-(1-trainR2)*((len(x_train)-1)/(len(x_train)-x_train.shape[2]-1))\n","    testAdjR2 = 1-(1-testR2)*((len(x_test)-1)/(len(x_test)-x_test.shape[2]-1))\n","\n","    dfscore = pd.DataFrame({'name':[f'{ID}', f'{ID}'],\n","                            'modelname':[f'{model_name}', f'{model_name}'],\n","                            'split': ['Train', 'Test'],\n","                            'RMSE': [trainRMSE, testRMSE],\n","                            'R2 Score': [trainR2, testR2],\n","                            'Adj R2 Score': [trainAdjR2, testAdjR2]})\n","\n","    return dfmseplot, dfpred, dfscore"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FTejjsHQzZt4"},"source":["# START"]},{"cell_type":"code","metadata":{"id":"QQH7ghSszZt4"},"source":["# 檔案讀取大表\n","f = pd.read_csv('/content/drive/MyDrive/Final Project/Final_Dataset/Second clean in Spark/clean_long_dataset.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"5udZ48FtIbFg","executionInfo":{"status":"ok","timestamp":1627224398474,"user_tz":-480,"elapsed":1549,"user":{"displayName":"group bdse","photoUrl":"","userId":"17605883566341682608"}},"outputId":"0620a82a-8b92-490e-f79f-9ffccd81d2a6"},"source":["f.tail()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>category</th>\n","      <th>name</th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>close</th>\n","      <th>volume</th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>day</th>\n","      <th>dayofyear</th>\n","      <th>weekofyear</th>\n","      <th>dayofweek</th>\n","      <th>ht_dcperiod</th>\n","      <th>ht_dcphase</th>\n","      <th>inphase</th>\n","      <th>quadrature</th>\n","      <th>sine</th>\n","      <th>leadsine</th>\n","      <th>ht_trendmode</th>\n","      <th>add</th>\n","      <th>div</th>\n","      <th>max23</th>\n","      <th>maxindex</th>\n","      <th>min25</th>\n","      <th>minindex</th>\n","      <th>min27</th>\n","      <th>max28</th>\n","      <th>minidx</th>\n","      <th>maxidx</th>\n","      <th>mult</th>\n","      <th>sub</th>\n","      <th>sum</th>\n","      <th>atan</th>\n","      <th>ceil</th>\n","      <th>cos</th>\n","      <th>cosh</th>\n","      <th>exp</th>\n","      <th>floor</th>\n","      <th>...</th>\n","      <th>cdlsticksandwich</th>\n","      <th>cdltakuri</th>\n","      <th>cdltasukigap</th>\n","      <th>cdlthrusting</th>\n","      <th>cdltristar</th>\n","      <th>cdlunique3river</th>\n","      <th>cdlupsidegap2crows</th>\n","      <th>cdlxsidegap3methods</th>\n","      <th>avgprice</th>\n","      <th>medprice</th>\n","      <th>typprice</th>\n","      <th>wclprice</th>\n","      <th>beta</th>\n","      <th>correl</th>\n","      <th>linearreg</th>\n","      <th>linearreg_angle</th>\n","      <th>linearreg_intercept</th>\n","      <th>linearreg_slope</th>\n","      <th>stddev</th>\n","      <th>tsf</th>\n","      <th>var</th>\n","      <th>atr</th>\n","      <th>natr</th>\n","      <th>trange</th>\n","      <th>ad</th>\n","      <th>adosc</th>\n","      <th>obv</th>\n","      <th>bias</th>\n","      <th>ama</th>\n","      <th>psy</th>\n","      <th>dpo</th>\n","      <th>vhf</th>\n","      <th>rvi</th>\n","      <th>BCI</th>\n","      <th>BCTI</th>\n","      <th>BDI</th>\n","      <th>BDTI</th>\n","      <th>BPI</th>\n","      <th>BSI</th>\n","      <th>NTD/USD</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>96754</th>\n","      <td>2021-06-24</td>\n","      <td>ExRate</td>\n","      <td>TWD/USD</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>28.002</td>\n","    </tr>\n","    <tr>\n","      <th>96755</th>\n","      <td>2021-06-25</td>\n","      <td>ExRate</td>\n","      <td>TWD/USD</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>27.907</td>\n","    </tr>\n","    <tr>\n","      <th>96756</th>\n","      <td>2021-06-28</td>\n","      <td>ExRate</td>\n","      <td>TWD/USD</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>27.910</td>\n","    </tr>\n","    <tr>\n","      <th>96757</th>\n","      <td>2021-06-29</td>\n","      <td>ExRate</td>\n","      <td>TWD/USD</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>27.908</td>\n","    </tr>\n","    <tr>\n","      <th>96758</th>\n","      <td>2021-06-30</td>\n","      <td>ExRate</td>\n","      <td>TWD/USD</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>27.870</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 199 columns</p>\n","</div>"],"text/plain":["             date category     name  open  high  ...  BDI  BDTI  BPI  BSI  NTD/USD\n","96754  2021-06-24   ExRate  TWD/USD   NaN   NaN  ...  NaN   NaN  NaN  NaN   28.002\n","96755  2021-06-25   ExRate  TWD/USD   NaN   NaN  ...  NaN   NaN  NaN  NaN   27.907\n","96756  2021-06-28   ExRate  TWD/USD   NaN   NaN  ...  NaN   NaN  NaN  NaN   27.910\n","96757  2021-06-29   ExRate  TWD/USD   NaN   NaN  ...  NaN   NaN  NaN  NaN   27.908\n","96758  2021-06-30   ExRate  TWD/USD   NaN   NaN  ...  NaN   NaN  NaN  NaN   27.870\n","\n","[5 rows x 199 columns]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"NRaVjjTkzZt5"},"source":["# 列出所有股票\n","names = list(f['name'].unique())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkrxfY3HzZt5"},"source":["# 紀錄一下各自的時間\n","timelist = []\n","metrics_score = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"FisKaDF8zZt5","colab":{"base_uri":"https://localhost:8080/","height":379},"executionInfo":{"status":"error","timestamp":1627270208394,"user_tz":-480,"elapsed":389,"user":{"displayName":"group bdse","photoUrl":"","userId":"17605883566341682608"}},"outputId":"c3f34d41-d78f-47d1-f86b-efab16bd3ad8"},"source":["for name in names[20:30]:\n","    \n","    # 參數設定\n","    ID = name \n","    lookback = 10\n","    test_set_size = 120\n","    epochs = 500\n","\n","    # 選取想要的股票\n","    df, alldate = stock(ID)\n","\n","    # 保留日期資訊\n","    alldatelist = list(alldate)\n","    train_date_list = alldatelist[lookback:-test_set_size]\n","    test_date_list = alldatelist[-test_set_size:]\n","\n","    # LSTM\n","    lstmstart = time.time()\n","    lstmdfmseplot, lstmdfpred, lstmdfscore = Stock_predict_process(ID, epochs, model_name = 'LSTM', \n","                                                                   train_date_list=train_date_list, test_date_list=test_date_list)\n","    lstmend = time.time()\n","    timelist.append(lstmend - lstmstart)\n","    timelist.append(lstmend - lstmstart) # 為了後面整理資料\n","\n","    # GRU\n","    grustart = time.time()\n","    grudfmseplot, grudfpred, grudfscore = Stock_predict_process(ID, epochs, model_name = 'GRU', \n","                                                                train_date_list=train_date_list, test_date_list=test_date_list)\n","    gruend = time.time()\n","    timelist.append(gruend - grustart)\n","    timelist.append(gruend - grustart)  # 為了後面整理資料\n","\n","    # LSTM_GRU_Data_Stock_Trend_Plot\n","    LSTM_GRU_Data_Stock_Trend_Plot(lstmdfpred[lstmdfpred['split']=='test'].loc[:,'historical'].values,\n","                                   lstmdfpred[lstmdfpred['split']=='test'].loc[:,'prediction_LSTM'].values, \n","                                   grudfpred[grudfpred['split']=='test'].loc[:,'prediction_GRU'].values,\n","                                   test_date_list=test_date_list, ID=ID)\n","\n","    # 存檔\n","    dfpred = pd.concat([lstmdfpred, grudfpred.loc[:,'prediction_GRU']], axis=1)\n","    dfmseplot = pd.concat([lstmdfmseplot, grudfmseplot], axis=1)\n","    dfscore = pd.concat([lstmdfscore, grudfscore]).reset_index(drop=True)\n","\n","    if os.path.exists('data/researchdata') is False:\n","        os.makedirs('data/researchdata')\n","\n","    dfpred.to_csv(f'data/researchdata/{ID}_Prediction_Data.csv', index=False)\n","    dfmseplot.to_csv(f'data/researchdata/{ID}_RMSE_MSELOSS_in_Training.csv', index=False)\n","    \n","    #dfscore.to_csv(f'data/researchdata/{ID}_Metrics_and_Score_.csv', index=False)\n","    metrics_score.append(dfscore)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexingError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-57e52e230321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 選取想要的股票\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malldate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# 保留日期資訊\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-1a3d1580e2fe>\u001b[0m in \u001b[0;36mstock\u001b[0;34m(id)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# 取出在long裡面的航運指數\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfutures_shipping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Futures'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BCI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BCTI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BDI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BDTI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BPI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BSI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#print(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0;31m# ugly hack for GH #836\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many indexers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexingError\u001b[0m: Too many indexers"]}]},{"cell_type":"code","metadata":{"id":"NAqXsa46zZt7"},"source":["all_metrics_score = pd.concat([x for x in metrics_score]).reset_index(drop=True)\n","all_metrics_score.insert(len(all_metrics_score.columns), 'time', timelist)\n","all_metrics_score.to_csv(f'data/researchdata/All_Metrics_Score_Time.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fS3ZVN0nzZt7"},"source":["lstm_time = []\n","gru_time = []\n","\n","for i in range(len(timelist)):   \n","    if i%4 == 0:\n","        lstm_time.append(timelist[i])\n","    if i%4 == 2:\n","        gru_time.append(timelist[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pqmL0CslzZt8"},"source":["dfalltime = pd.DataFrame({'name':names[:30],\n","                       'lstm_time':lstm_time,\n","                       'gru_time':gru_time})\n","\n","dfalltime.to_csv(f'data/researchdata/All_Time.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ks7_ZjuYzZt8"},"source":["##### just test"]},{"cell_type":"code","metadata":{"id":"3BTXYERHzZt8"},"source":["# load the model\n","\n","# modelG = GRU(input_dim=df.shape[1], hidden_dim=32, output_dim=1, num_layers=2).to(device)\n","# modelG.load_state_dict(torch.load('data/model/GRU_epoch500.pth')) \n","\n","# y_test_pred = modelG(x_test)\n","# y_test_predG = scalertar.inverse_transform(y_test_pred.cpu().detach().numpy())\n","\n","# y_test_predG\n","# all_y_test_pred[-1]"],"execution_count":null,"outputs":[]}]}